{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lecture34.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wdconinc/practical-computing-for-scientists/blob/master/Lectures/lecture34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0aH_RqD-fJy-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lecture 34: Machine Learning"
      ]
    },
    {
      "metadata": {
        "id": "s9oqusiKJa0P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Last Episode"
      ]
    },
    {
      "metadata": {
        "id": "7kMVy3sKJrDu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Artificial neural networks\n",
        "- using non-linear activation functions\n",
        "- example: diabetes score\n",
        "- example: MNIST handwriting recognition"
      ]
    },
    {
      "metadata": {
        "id": "1yU9gJDOPlZv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preamble"
      ]
    },
    {
      "metadata": {
        "id": "3sCC3EQj-An1",
        "colab_type": "code",
        "outputId": "f218808a-32a0-4c35-ddab-e535941aadef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3157
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn as sk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for graph plots\n",
        "!apt install -q -y graphviz\n",
        "!pip install graphviz\n",
        "import graphviz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  fontconfig libann0 libcairo2 libcdt5 libcgraph6 libdatrie1 libgd3\n",
            "  libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libjbig0 liblab-gamut1 libltdl7\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpathplan4\n",
            "  libpixman-1-0 libthai-data libthai0 libtiff5 libwebp6 libxaw7 libxcb-render0\n",
            "  libxcb-shm0 libxmu6 libxpm4 libxt6\n",
            "Suggested packages:\n",
            "  gsfonts graphviz-doc libgd-tools\n",
            "The following NEW packages will be installed:\n",
            "  fontconfig graphviz libann0 libcairo2 libcdt5 libcgraph6 libdatrie1 libgd3\n",
            "  libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libjbig0 liblab-gamut1 libltdl7\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpathplan4\n",
            "  libpixman-1-0 libthai-data libthai0 libtiff5 libwebp6 libxaw7 libxcb-render0\n",
            "  libxcb-shm0 libxmu6 libxpm4 libxt6\n",
            "0 upgraded, 30 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 4,154 kB of archives.\n",
            "After this operation, 16.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig amd64 2.12.6-0ubuntu2 [169 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libann0 amd64 1.1.2+doc-6 [24.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcdt5 amd64 2.40.1-2 [19.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcgraph6 amd64 2.40.1-2 [40.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig0 amd64 2.1-3.1build1 [26.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtiff5 amd64 4.0.9-5 [152 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwebp6 amd64 0.6.1-2 [185 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxpm4 amd64 1:3.5.12-1 [34.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgd3 amd64 2.2.5-4ubuntu0.2 [119 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-0.7-5 amd64 0.7.6+darcs121130-4 [150 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-0 amd64 0.34.0-2 [229 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-render0 amd64 1.13-1 [14.7 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-shm0 amd64 1.13-1 [5,572 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcairo2 amd64 1.15.10-2 [580 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libltdl7 amd64 2.4.6-2 [38.8 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai-data all 0.1.27-2 [133 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdatrie1 amd64 0.2.10-7 [17.8 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai0 amd64 0.1.27-2 [18.0 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango-1.0-0 amd64 1.40.14-1ubuntu0.1 [153 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoft2-1.0-0 amd64 1.40.14-1ubuntu0.1 [33.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangocairo-1.0-0 amd64 1.40.14-1ubuntu0.1 [20.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libpathplan4 amd64 2.40.1-2 [22.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvc6 amd64 2.40.1-2 [601 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvpr2 amd64 2.40.1-2 [169 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/universe amd64 liblab-gamut1 amd64 2.40.1-2 [178 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxt6 amd64 1:1.1.5-1 [160 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmu6 amd64 2:1.1.2-2 [46.0 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxaw7 amd64 2:1.0.13-1 [173 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 graphviz amd64 2.40.1-2 [601 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-bin amd64 0.7.6+darcs121130-4 [41.3 kB]\n",
            "Fetched 4,154 kB in 8s (498 kB/s)\n",
            "Selecting previously unselected package fontconfig.\n",
            "(Reading database ... 26397 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fontconfig_2.12.6-0ubuntu2_amd64.deb ...\n",
            "Unpacking fontconfig (2.12.6-0ubuntu2) ...\n",
            "Selecting previously unselected package libann0.\n",
            "Preparing to unpack .../01-libann0_1.1.2+doc-6_amd64.deb ...\n",
            "Unpacking libann0 (1.1.2+doc-6) ...\n",
            "Selecting previously unselected package libcdt5.\n",
            "Preparing to unpack .../02-libcdt5_2.40.1-2_amd64.deb ...\n",
            "Unpacking libcdt5 (2.40.1-2) ...\n",
            "Selecting previously unselected package libcgraph6.\n",
            "Preparing to unpack .../03-libcgraph6_2.40.1-2_amd64.deb ...\n",
            "Unpacking libcgraph6 (2.40.1-2) ...\n",
            "Selecting previously unselected package libjbig0:amd64.\n",
            "Preparing to unpack .../04-libjbig0_2.1-3.1build1_amd64.deb ...\n",
            "Unpacking libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Selecting previously unselected package libtiff5:amd64.\n",
            "Preparing to unpack .../05-libtiff5_4.0.9-5_amd64.deb ...\n",
            "Unpacking libtiff5:amd64 (4.0.9-5) ...\n",
            "Selecting previously unselected package libwebp6:amd64.\n",
            "Preparing to unpack .../06-libwebp6_0.6.1-2_amd64.deb ...\n",
            "Unpacking libwebp6:amd64 (0.6.1-2) ...\n",
            "Selecting previously unselected package libxpm4:amd64.\n",
            "Preparing to unpack .../07-libxpm4_1%3a3.5.12-1_amd64.deb ...\n",
            "Unpacking libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Selecting previously unselected package libgd3:amd64.\n",
            "Preparing to unpack .../08-libgd3_2.2.5-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking libgd3:amd64 (2.2.5-4ubuntu0.2) ...\n",
            "Selecting previously unselected package libgts-0.7-5:amd64.\n",
            "Preparing to unpack .../09-libgts-0.7-5_0.7.6+darcs121130-4_amd64.deb ...\n",
            "Unpacking libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
            "Selecting previously unselected package libpixman-1-0:amd64.\n",
            "Preparing to unpack .../10-libpixman-1-0_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-render0:amd64.\n",
            "Preparing to unpack .../11-libxcb-render0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-render0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libxcb-shm0:amd64.\n",
            "Preparing to unpack .../12-libxcb-shm0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-shm0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libcairo2:amd64.\n",
            "Preparing to unpack .../13-libcairo2_1.15.10-2_amd64.deb ...\n",
            "Unpacking libcairo2:amd64 (1.15.10-2) ...\n",
            "Selecting previously unselected package libltdl7:amd64.\n",
            "Preparing to unpack .../14-libltdl7_2.4.6-2_amd64.deb ...\n",
            "Unpacking libltdl7:amd64 (2.4.6-2) ...\n",
            "Selecting previously unselected package libthai-data.\n",
            "Preparing to unpack .../15-libthai-data_0.1.27-2_all.deb ...\n",
            "Unpacking libthai-data (0.1.27-2) ...\n",
            "Selecting previously unselected package libdatrie1:amd64.\n",
            "Preparing to unpack .../16-libdatrie1_0.2.10-7_amd64.deb ...\n",
            "Unpacking libdatrie1:amd64 (0.2.10-7) ...\n",
            "Selecting previously unselected package libthai0:amd64.\n",
            "Preparing to unpack .../17-libthai0_0.1.27-2_amd64.deb ...\n",
            "Unpacking libthai0:amd64 (0.1.27-2) ...\n",
            "Selecting previously unselected package libpango-1.0-0:amd64.\n",
            "Preparing to unpack .../18-libpango-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
            "Preparing to unpack .../19-libpangoft2-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
            "Preparing to unpack .../20-libpangocairo-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpathplan4.\n",
            "Preparing to unpack .../21-libpathplan4_2.40.1-2_amd64.deb ...\n",
            "Unpacking libpathplan4 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvc6.\n",
            "Preparing to unpack .../22-libgvc6_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvc6 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvpr2.\n",
            "Preparing to unpack .../23-libgvpr2_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvpr2 (2.40.1-2) ...\n",
            "Selecting previously unselected package liblab-gamut1.\n",
            "Preparing to unpack .../24-liblab-gamut1_2.40.1-2_amd64.deb ...\n",
            "Unpacking liblab-gamut1 (2.40.1-2) ...\n",
            "Selecting previously unselected package libxt6:amd64.\n",
            "Preparing to unpack .../25-libxt6_1%3a1.1.5-1_amd64.deb ...\n",
            "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
            "Selecting previously unselected package libxmu6:amd64.\n",
            "Preparing to unpack .../26-libxmu6_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package libxaw7:amd64.\n",
            "Preparing to unpack .../27-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
            "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Selecting previously unselected package graphviz.\n",
            "Preparing to unpack .../28-graphviz_2.40.1-2_amd64.deb ...\n",
            "Unpacking graphviz (2.40.1-2) ...\n",
            "Selecting previously unselected package libgts-bin.\n",
            "Preparing to unpack .../29-libgts-bin_0.7.6+darcs121130-4_amd64.deb ...\n",
            "Unpacking libgts-bin (0.7.6+darcs121130-4) ...\n",
            "Setting up libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
            "Setting up libpathplan4 (2.40.1-2) ...\n",
            "Setting up liblab-gamut1 (2.40.1-2) ...\n",
            "Setting up libxcb-render0:amd64 (1.13-1) ...\n",
            "Setting up libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Setting up libdatrie1:amd64 (0.2.10-7) ...\n",
            "Setting up libtiff5:amd64 (4.0.9-5) ...\n",
            "Setting up libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libltdl7:amd64 (2.4.6-2) ...\n",
            "Setting up libann0 (1.1.2+doc-6) ...\n",
            "Setting up libxcb-shm0:amd64 (1.13-1) ...\n",
            "Setting up libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up libgts-bin (0.7.6+darcs121130-4) ...\n",
            "Setting up libthai-data (0.1.27-2) ...\n",
            "Setting up libcdt5 (2.40.1-2) ...\n",
            "Setting up fontconfig (2.12.6-0ubuntu2) ...\n",
            "Regenerating fonts cache... done.\n",
            "Setting up libcgraph6 (2.40.1-2) ...\n",
            "Setting up libwebp6:amd64 (0.6.1-2) ...\n",
            "Setting up libcairo2:amd64 (1.15.10-2) ...\n",
            "Setting up libgvpr2 (2.40.1-2) ...\n",
            "Setting up libgd3:amd64 (2.2.5-4ubuntu0.2) ...\n",
            "Setting up libthai0:amd64 (0.1.27-2) ...\n",
            "Setting up libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Setting up libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Setting up libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libgvc6 (2.40.1-2) ...\n",
            "Setting up graphviz (2.40.1-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Collecting graphviz\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/e2/ef2581b5b86625657afd32030f90cf2717456c1d2b711ba074bf007c0f1a/graphviz-0.10.1-py2.py3-none-any.whl\n",
            "Installing collected packages: graphviz\n",
            "Successfully installed graphviz-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ck43igQlC8w0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Handwriting Recognition with Artificial Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "OSiBw24yDt7G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We looked at a problem which we cannot solve in traditional ways: recognition of handwritten digits (a standard machine learning problem)."
      ]
    },
    {
      "metadata": {
        "id": "cC28Tl726HYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's first get the MNIST data set\n",
        "from sklearn.datasets import fetch_mldata\n",
        "mnist = fetch_mldata(\"MNIST original\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YMq3PmxqLay0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As usual we split the data into a training and test data set."
      ]
    },
    {
      "metadata": {
        "id": "-7IrhvUQEC54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use a random permutation\n",
        "np.random.seed(0)\n",
        "perm = np.arange(len(mnist.data))\n",
        "perm = np.random.permutation(len(mnist.data))\n",
        "\n",
        "# Rescale, split in training and test data\n",
        "X, y = mnist.data[perm] / 255., mnist.target[perm]\n",
        "X_train, X_test = X[:60000], X[60000:]\n",
        "y_train, y_test = y[:60000], y[60000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o9oMCIBPL0AK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's create an artificial neural network classifier that has a hidden layer with 100 nodes and ReLU activation function."
      ]
    },
    {
      "metadata": {
        "id": "UHVVyXCbEa4R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, ), max_iter=40, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-3, random_state=1,\n",
        "                    learning_rate_init=.1, activation = \"relu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_s5uJDRUF0od",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now train our network. This may take a while... (even if the tolerance is set to a fairly large value)"
      ]
    },
    {
      "metadata": {
        "id": "-CHJll11FzRm",
        "colab_type": "code",
        "outputId": "2edc08b5-2e53-49fb-c03e-a7380acf430c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "cell_type": "code",
      "source": [
        "mlp.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.29249660\n",
            "Iteration 2, loss = 0.12361080\n",
            "Iteration 3, loss = 0.09000660\n",
            "Iteration 4, loss = 0.07097907\n",
            "Iteration 5, loss = 0.05806030\n",
            "Iteration 6, loss = 0.04855646\n",
            "Iteration 7, loss = 0.04091454\n",
            "Iteration 8, loss = 0.03512452\n",
            "Iteration 9, loss = 0.02940072\n",
            "Iteration 10, loss = 0.02546369\n",
            "Iteration 11, loss = 0.02171612\n",
            "Iteration 12, loss = 0.01749820\n",
            "Iteration 13, loss = 0.01542681\n",
            "Iteration 14, loss = 0.01283184\n",
            "Iteration 15, loss = 0.01078268\n",
            "Iteration 16, loss = 0.00875058\n",
            "Iteration 17, loss = 0.00711103\n",
            "Iteration 18, loss = 0.00634392\n",
            "Iteration 19, loss = 0.00510398\n",
            "Iteration 20, loss = 0.00475525\n",
            "Iteration 21, loss = 0.00382842\n",
            "Iteration 22, loss = 0.00351482\n",
            "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=40, momentum=0.9,\n",
              "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
              "       solver='sgd', tol=0.001, validation_fraction=0.1, verbose=10,\n",
              "       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "89KY0So9MdYK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "However, even with this level of training we already obtain very good results on the test data set. The scores below are the accuracy scores: i.e. 0.99 means a 99% accuracy."
      ]
    },
    {
      "metadata": {
        "id": "ZRi6A_ZMFXxu",
        "colab_type": "code",
        "outputId": "b60ea9cd-4032-45b2-c2c4-dd624938d6c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
        "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.999950\n",
            "Test set score: 0.978000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rxz7IU7O2p72",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### How Can We Do Better?"
      ]
    },
    {
      "metadata": {
        "id": "Sy60Rwki2twK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If we think about the draw backs of the artificial neural network we used above, then one should jump out right away: the algorithm does not inherently understand that a shifted or scaled image should result in the same classification. The same '7' drawn slightly more to the left or to the right is still a '7', but to an artificial neural network with 784 input features this looks like an entirely different thing. Can we think of a way to build in this position and scale invariance? This is where *convolutional neural networks* bring us a solution.\n",
        "\n",
        "\n",
        "#### Convolution in the time domain: a reminder\n",
        "We will use a concept we introduced earlier, in the section on digital signal procession: *convolution*.  Remember how we defined this then:\n",
        "$$ (f * g)(t) = \\int_{-\\infty}^{+\\infty} f(t - \\tau) g(\\tau) d\\tau $$\n",
        "in the time domain.\n",
        "\n",
        "#### Convolution in the image domain\n",
        "Now we will use a similar convolution but in the 2-dimensional image domain. We mentioned this approach in the context of convolution in digital signal processing already when we discussed point-spread functions in digital image processing: the registered image is the original image convoluted with the point-spread function of the optics of the camera's lens system.\n",
        "\n",
        "In our case we will talk about the convolution *kernel* as a *filter* or *feature detector* and the convolution with the input image map will be *activation map* or *feature map*.\n",
        "\n",
        "Let's say we wish to take the convolution of the $5 \\times 5$ black/white input image on the left with the $3 \\times 3$ kernel on the right:\n",
        "\n",
        "<img src=\"https://ujwlkarn.files.wordpress.com/2016/07/screen-shot-2016-07-24-at-11-25-13-pm.png\" width=\"46%\"> <img src=\"https://ujwlkarn.files.wordpress.com/2016/07/screen-shot-2016-07-24-at-11-25-24-pm.png\" width=\"49%\">\n",
        "\n",
        "We will obtain a new $3 \\times 3$ activation map with the product values of the corresponding pixels as we shift the convolution kernel (with *stride* equal to 1) across the image:\n",
        "\n",
        "<img src=\"https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif\" width=\"66%\">\n",
        "\n",
        "We can extend this to any $n \\times n$ input image (with $p$ pixels of padding) and any $m \\times m$ kernel with stride $k$ to obtain an $n' \\times n'$ activation map with\n",
        "$$ n' = \\frac{n - m + 2 \\cdot p}{k} + 1 $$\n",
        "Indeed: $n' = \\frac{5 - 3 + 2 \\cdot 0}{1} + 1 = 3$\n",
        "\n",
        "Although we might want the activation map to be normalized if we continue to think in terms of images, there is no requirement that this is the case. It is just a map which tells us where a certain feature is activated.\n",
        "\n",
        "#### Various convolution kernels\n",
        "Certain convolution kernels will perform different functions:\n",
        "\n",
        "<img src=\"https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-05-at-11-03-00-pm.png\" width=\"50%\" align=\"middle\">\n",
        "\n",
        "#### Convolutional kernels in neural networks\n",
        "In our convolution neural networks we will use a non-linear activation function (e.g. ReLU) on the output of the convolution step, we will let the training algorithm decide on the optimal configuration of the kernel, and we will allow the use of $q$ kernels (or filters). As the output of our convolution layer we will therefore have $n' \\times n' \\times q$ output values.\n",
        "\n",
        "#### Pooling for position invariance\n",
        "The next step in convolutional neural networks is typically a *pooling layer* where we reduce the full $n' \\times n'$ activation map to a smaller map by downsampling to the sum or maximum of a range of pixels, e.g. the maximum in a $5 \\times 5$ range. A large activation for a particular feature anywhere in this $5 \\times 5$ area of the input image will now activate the same pixel in the pooled feature map and we have obtained invariance under shifts."
      ]
    },
    {
      "metadata": {
        "id": "YTtQ-cxLnjcn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-9-15-21-pm.png\" width=\"80%\">"
      ]
    },
    {
      "metadata": {
        "id": "OnBZmWboH4tK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras: A Professional Machine Learning Tool"
      ]
    },
    {
      "metadata": {
        "id": "OnH51sfNSYlZ",
        "colab_type": "code",
        "outputId": "0e77202b-7da5-49e2-c7e1-6fd6af42ef0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IWn5cj6aHzLf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation = 'relu', input_shape = (784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QtMTp1ZkIEJI",
        "colab_type": "code",
        "outputId": "865151aa-4ee0-4953-c84e-2031ed08f6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5KAlJ4aeIGcT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.Adadelta(),\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LTMj-OymIIBB",
        "colab_type": "code",
        "outputId": "39ac26ad-b7ff-44a5-e28c-5e7753b27d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.2885 - acc: 0.9131 - val_loss: 0.1183 - val_acc: 0.9625\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1157 - acc: 0.9651 - val_loss: 0.0914 - val_acc: 0.9720\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0819 - acc: 0.9750 - val_loss: 0.0829 - val_acc: 0.9738\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0619 - acc: 0.9811 - val_loss: 0.0659 - val_acc: 0.9792\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0501 - acc: 0.9835 - val_loss: 0.0669 - val_acc: 0.9786\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0396 - acc: 0.9869 - val_loss: 0.0579 - val_acc: 0.9815\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0328 - acc: 0.9892 - val_loss: 0.0651 - val_acc: 0.9823\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0286 - acc: 0.9909 - val_loss: 0.0584 - val_acc: 0.9833\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0234 - acc: 0.9928 - val_loss: 0.0618 - val_acc: 0.9819\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0213 - acc: 0.9931 - val_loss: 0.0609 - val_acc: 0.9822\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0184 - acc: 0.9939 - val_loss: 0.0612 - val_acc: 0.9833\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0167 - acc: 0.9945 - val_loss: 0.0618 - val_acc: 0.9835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-EIKoXEeIJV1",
        "colab_type": "code",
        "outputId": "a72d481f-249a-4328-bbeb-a2bf153fd63a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose = 0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.06182534301124979\n",
            "Test accuracy: 0.9835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8tbiHUuF2OV_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convolutional Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "gi4xtt1Y9m1n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, \n",
        "                 kernel_size = (3, 3),\n",
        "                 activation = 'relu',\n",
        "                 input_shape = input_shape))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size = (3, 3),\n",
        "                 activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ax-TdRHmL22-",
        "outputId": "a1d9dd83-a7b2-4112-f2c0-ce6e7494cd0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v-two6ZI9hsK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = keras.losses.categorical_crossentropy,\n",
        "              optimizer = keras.optimizers.Adadelta(),\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EPw5P26M9VTD",
        "colab_type": "code",
        "outputId": "b113a38a-66a0-44a6-ac3e-f176292642ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size = batch_size,\n",
        "          epochs = epochs,\n",
        "          verbose = 1,\n",
        "          validation_data = (x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.2547 - acc: 0.9220 - val_loss: 0.0665 - val_acc: 0.9790\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0853 - acc: 0.9748 - val_loss: 0.0488 - val_acc: 0.9839\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.0640 - acc: 0.9812 - val_loss: 0.0345 - val_acc: 0.9876\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.0534 - acc: 0.9841 - val_loss: 0.0347 - val_acc: 0.9890\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0450 - acc: 0.9864 - val_loss: 0.0310 - val_acc: 0.9899\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0422 - acc: 0.9871 - val_loss: 0.0296 - val_acc: 0.9899\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0357 - acc: 0.9887 - val_loss: 0.0284 - val_acc: 0.9906\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0326 - acc: 0.9903 - val_loss: 0.0331 - val_acc: 0.9897\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0313 - acc: 0.9905 - val_loss: 0.0304 - val_acc: 0.9900\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.0286 - acc: 0.9911 - val_loss: 0.0273 - val_acc: 0.9920\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0287 - val_acc: 0.9907\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0243 - acc: 0.9925 - val_loss: 0.0295 - val_acc: 0.9913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f51e01c0240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "vNrkjTtV9XIX",
        "colab_type": "code",
        "outputId": "d16a1f4b-e898-46de-84df-7e3b6b90e170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose = 0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.029486772899981223\n",
            "Test accuracy: 0.9913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9vLSvXoyOL0j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}